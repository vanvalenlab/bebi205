{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwZ3Hl_SEfxf"
   },
   "source": [
    "# Sequences\n",
    "[![Open in Colab](https://img.shields.io/static/v1?logo=google-colab&message=Open%20in%20colab&color=blue&label=%20&labelColor=5c5c5c)](https://colab.research.google.com/github/vanvalenlab/bebi205/blob/master/bebi205/notebooks/sequences.ipynb)\n",
    "[![Open key in Colab](https://img.shields.io/static/v1?logo=google-colab&message=Open%20key%20in%20colab&color=blue&label=%20&labelColor=5c5c5c)](https://colab.research.google.com/github/vanvalenlab/bebi205/blob/master/bebi205/notebooks/sequences-key.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S9U8IgSEJHZx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxdcXNGvFcYN"
   },
   "source": [
    "At the most basic level, sequences are simply a string and could be manipulated as such. However, the Biopython library provides a sophisticated set of tools for reading, annotating and manipulating biological sequence data. In this notebook we will look at a few example use cases of the Biopython libary to demonstrate how sequences can be handled as data. These examples are adapted from the [Biopython Tutorial and Cookbook](http://biopython.org/DIST/docs/tutorial/Tutorial.html) (Biopython version 1.78).\n",
    "\n",
    "Some code cells will be marked with \n",
    "```\n",
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "```\n",
    "\n",
    "This indicates that you are being asked to write a piece of code to complete the notebook.\n",
    "\n",
    "To get started, we will use pip to install the Biopython package if it's not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C502MpDdGDI2",
    "outputId": "74695a1b-cefd-4280-c48f-4ed6efdb6479",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/cd/0098eaff841850c01da928c7f509b72fd3e1f51d77b772e24de9e2312471/biopython-1.78-cp37-cp37m-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
      "Installing collected packages: biopython\n",
      "Successfully installed biopython-1.78\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFIpzQCyKM3o"
   },
   "source": [
    "## Reading Sequence Files\n",
    "We are going to look at some data from a recent paper published by Bryan Branson's group at MIT. We'll looked at the paper in more detail before Professor Branson gives a guest lecture later in the course.\n",
    "\n",
    "Hie, B., Zhong, E. D., Berger, B., & Bryson, B. (2021). [Learning the language of viral evolution and escape.](https://doi.org/10.1126/science.abd7331) Science, 371(6526), 284-288."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN607f41e_qp",
    "outputId": "f9f6c8bd-4fa4-445e-853f-ff3806b395d8",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-15 20:10:54--  http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n",
      "Resolving cb.csail.mit.edu (cb.csail.mit.edu)... 128.30.2.148\n",
      "Connecting to cb.csail.mit.edu (cb.csail.mit.edu)|128.30.2.148|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 74057478 (71M) [application/x-gzip]\n",
      "Saving to: ‘data.tar.gz’\n",
      "\n",
      "data.tar.gz         100%[===================>]  70.63M  6.67MB/s    in 6.5s    \n",
      "\n",
      "2021-03-15 20:11:01 (10.9 MB/s) - ‘data.tar.gz’ saved [74057478/74057478]\n",
      "\n",
      "data/\n",
      "data/escape_results.txt\n",
      "data/evcouplings/\n",
      "data/evcouplings/flu_h3_config.yaml\n",
      "data/evcouplings/flu_h1_config.yaml\n",
      "data/evcouplings/hiv_bf520_seq.fa\n",
      "data/evcouplings/hiv_env_seq.fa\n",
      "data/evcouplings/hiv_env_config.yaml\n",
      "data/evcouplings/sarscov2_config.yaml\n",
      "data/evcouplings/flu_h1_seq.fa\n",
      "data/evcouplings/hiv_bf520_config.yaml\n",
      "data/evcouplings/sarscov2_seq.fa\n",
      "data/evcouplings/flu_h3_seq.fa\n",
      "data/headlines/\n",
      "data/headlines/abcnews-date-text.csv\n",
      "data/hiv/\n",
      "data/hiv/bg505_regions.txt\n",
      "data/hiv/fitness_haddox2018/\n",
      "data/hiv/fitness_haddox2018/BG505-1_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BG505-3_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BG505-2_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BF520-3_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BF520-2_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BF520-1_prefs.csv\n",
      "data/hiv/fitness_haddox2018/BF520_to_HXB2.csv\n",
      "data/hiv/fitness_haddox2018/BF520_env.fasta\n",
      "data/hiv/fitness_haddox2018/map_indices.py\n",
      "data/hiv/fitness_haddox2018/BF520_avgprefs.csv\n",
      "data/hiv/fitness_haddox2018/Env_protalignment_manualtweaks.fasta\n",
      "data/hiv/fitness_haddox2018/BG505_env.fasta\n",
      "data/hiv/fitness_haddox2018/BG505_avgprefs.csv\n",
      "data/hiv/fitness_haddox2018/BG505_to_HXB2.csv\n",
      "data/hiv/HIV-1_env_samelen.fa\n",
      "data/hiv/escape_dingens2019/\n",
      "data/hiv/escape_dingens2019/FileS4/\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/VRC34.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT151.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/VRC01.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/10E8.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/3BNC117.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT145.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/PGT121.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/101074.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/PG9.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurvive/3BNC117-101074-pool.csv\n",
      "data/hiv/escape_dingens2019/FileS4/.DS_Store\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PG9.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT151.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/3BNC117.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/3BNC117-101074-pool.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT121.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/101074.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/VRC34.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/PGT145.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/VRC01.csv\n",
      "data/hiv/escape_dingens2019/FileS4/fracsurviveaboveavg/10E8.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/PGT121.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/101074.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/PGT145.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/10E8.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/.DS_Store\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/PG9.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/VRC34.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/3BNC117.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/3BNC117-101074-pool.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/VRC01.csv\n",
      "data/hiv/escape_dingens2019/FileS4/diffsel/PGT151.csv\n",
      "data/hiv/escape_dingens2019/BG505_to_HXB2.csv\n",
      "data/hiv/escape_dingens2019/Env_protalign_manualeditAD.fasta\n",
      "data/fitness_results.txt\n",
      "data/influenza/\n",
      "data/influenza/escape_lee2019/\n",
      "data/influenza/escape_lee2019/H3_site_to_PDB_4o5n.csv\n",
      "data/influenza/escape_lee2019/avg_sel_tidy.csv\n",
      "data/influenza/escape_lee2019/Perth2009_H3_HA.fa\n",
      "data/influenza/fitness_wu2020/\n",
      "data/influenza/fitness_wu2020/data_all.csv\n",
      "data/influenza/fitness_wu2020/HA_ecto.fa\n",
      "data/influenza/fitness_wu2020/data_pref.tsv\n",
      "data/influenza/fitness_wu2020/HumanH3N2_All_2018.fa\n",
      "data/influenza/fitness_wu2020/wildtypes.fa\n",
      "data/influenza/escape_doud2018/\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_FI6v3_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L7_median.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_S139_median.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_C179_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L7_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_FI6v3_median.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_C179_median.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L10_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_S139_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L19_median.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L19_median_avgsite.csv\n",
      "data/influenza/escape_doud2018/medianfracsurvivefiles/antibody_H17L10_median.csv\n",
      "data/influenza/escape_doud2018/pos_map.csv\n",
      "data/influenza/escape_doud2018/H1toH3_renumber.csv\n",
      "data/influenza/escape_doud2018/WSN1933_H1_HA.fa\n",
      "data/influenza/escape_doud2018/candidates.fa\n",
      "data/influenza/ird_influenzaA_HA_allspecies.fa\n",
      "data/influenza/ird_influenzaA_HA_allspecies_meta.tsv\n",
      "data/influenza/h3_regions.txt\n",
      "data/influenza/h1_regions.txt\n",
      "data/influenza/fitness_doud2016/\n",
      "data/influenza/fitness_doud2016/Supplemental_File_5_sequencing_library_primers.txt\n",
      "data/influenza/fitness_doud2016/Supplemental_File_3_HApreferences_rescaled.txt\n",
      "data/influenza/fitness_doud2016/Doud2016_HA_replicate-2_prefs.csv\n",
      "data/influenza/fitness_doud2016/Doud2016_HA_replicate-3_prefs.csv\n",
      "data/influenza/fitness_doud2016/Doud2016_HA_replicate-1_prefs.csv\n",
      "data/influenza/fitness_doud2016/Supplemental_File_2_HApreferences.txt\n",
      "data/influenza/fitness_doud2016/Supplemental_File_6_WSN_to_H3_numbering_conversion.txt\n",
      "data/cov/\n",
      "data/cov/cov_all.fa\n",
      "data/cov/cov2_spike_wt.fasta\n",
      "data/cov/starr2020cov2/\n",
      "data/cov/starr2020cov2/binding_Kds.csv\n",
      "data/cov/starr2020cov2/expression_meanFs.csv\n",
      "data/cov/starr2020cov2/single_mut_effects.csv\n",
      "data/cov/gisaid.fasta\n",
      "data/cov/sarscov2_regions.txt\n",
      "data/cov/viprbrc_db.fasta\n",
      "data/cov/sars_cov2_seqs.fa\n",
      "data/greaney2020cov2/\n",
      "data/greaney2020cov2/escape_fracs.csv\n",
      "data/greaney2020cov2/significant_escape_sites.csv\n"
     ]
    }
   ],
   "source": [
    "!wget http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n",
    "!tar xvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gSDjxticfEta"
   },
   "outputs": [],
   "source": [
    "# Define file path constants\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir,'data')\n",
    "\n",
    "fname = 'data/influenza/ird_influenzaA_HA_allspecies.fa'\n",
    "meta_fname = 'data/influenza/ird_influenzaA_HA_allspecies_meta.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTtUhD8dGfHy"
   },
   "source": [
    "We are going to start by looking at a fasta file which is a standard text-based format for biological sequence data. We first print out the first 500 characters of the file to see how it is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AnI_OSyGqD-",
    "outputId": "39c58e11-d940-4eb1-a9fb-04c0b70f0bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">gb:K00429|ncbiId:AAR96248.1|UniProtKB:Q6LEJ4|Organism:Influenza A virus (A/seal/Mass/1/1980(H7N7))|Strain Name:A/seal/Mass/1/1980|Protein Name:HA Hemagglutinin|Gene Symbol:HA|Segment:4|Subtype:H7N7|Host:Sea Mammal\n",
      "MNTQILVFIACVLIEAKGDKICLGHHAVANGTKVNTLTERGIEVVNATETVETANIGKICTQGKRPTDLG\n",
      "QCGLLGTLIGPPQCDQFLEFESNLIIERREGNDVCYPGKFTNEESLRQILRGSGGVDKESMGFTYSGIRT\n",
      "NGTTSACRRSGSSFYAEMKWLLSNSDNAAFPQMTKSYRNPRNKPALIVWGIHHSGSTTEQTRLYGSGNKL\n",
      "ITVGSSKYQQSFTPSPGARPQVNGQSGRIDFHWLLLDPNDTVTFTFNGAFIAPNRASFFRGESLGVQSDV\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "with open(fname,'r') as f:\n",
    "    print(f.read(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wog7e2tIL4E7"
   },
   "source": [
    "Each record in the fasta file begins with a header line preceded by `>`. Now, we can open the file using the Biopython `SeqIO` parser. `Bio.SeqIO` provides suppport for many different sequence file formats. Check out the [docs](https://biopython.org/wiki/SeqIO) to see a comprehensive list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gjCTfqsYMEvi"
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jENoppr6Hcjs",
    "outputId": "b20b9136-eb5f-4897-af32-e09e2dc133d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb:K00429|ncbiId:AAR96248.1|UniProtKB:Q6LEJ4|Organism:Influenza\n",
      "Seq('MNTQILVFIACVLIEAKGDKICLGHHAVANGTKVNTLTERGIEVVNATETVETA...ICI')\n",
      "560\n",
      "gb:J02176|ncbiId:AAA43209.1|UniProtKB:P03454|Organism:Influenza\n",
      "Seq('MKAKLLVLLYAFVATDADTICIGYHANNSTDTVDTIFEKNVAVTHSVNLLEDRH...ICI')\n",
      "565\n",
      "gb:CY021709|ncbiId:ABP49327.1|UniProtKB:A4U6V2|Organism:Influenza\n",
      "Seq('MKARLLVLLCALAATDADTICIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDSH...ICI')\n",
      "566\n",
      "gb:CY020285|ncbiId:ABO38054.1|UniProtKB:A4GBW6|Organism:Influenza\n",
      "Seq('MKARLLVLLCALAATDADTICIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDSH...ICI')\n",
      "566\n",
      "gb:CY083910|ncbiId:ADX98960.1|UniProtKB:F0TT51|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFVTANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY063606|ncbiId:ADH01958.1|UniProtKB:D7ECP4|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY083776|ncbiId:ADX98792.1|UniProtKB:F0TSN3|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY073725|ncbiId:ADN05226.1|UniProtKB:E0V7J5|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY062691|ncbiId:ADG42153.1|UniProtKB:D5XJG9|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY062699|ncbiId:ADG42163.1|UniProtKB:D5XJH9|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY066935|ncbiId:ADK33671.1|UniProtKB:D8KV23|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n",
      "gb:CY066943|ncbiId:ADK33681.1|UniProtKB:D8KV33|Organism:Influenza\n",
      "Seq('MKAILVVLLYTFATANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKH...ICI')\n",
      "566\n"
     ]
    }
   ],
   "source": [
    "for i,seq_record in enumerate(SeqIO.parse(fname, 'fasta')):\n",
    "    print(seq_record.id)\n",
    "    print(repr(seq_record.seq))\n",
    "    print(len(seq_record))\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRG7e-w3NU1J"
   },
   "source": [
    "## Sequence Manipulations\n",
    "Biopython provides some useful tools for manipulating sequences some of which are biology specific while others act as if on basic strings. So far we've looked at amino acid sequences, but Biopython also supports DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3EOQDR4KOGbt"
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5-S6FH4HrsC",
    "outputId": "4b499be2-38d5-4244-fca0-71870777d11e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement: TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n",
      "Reverse complement: CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n"
     ]
    }
   ],
   "source": [
    "# Generate the complement or reverse complement\n",
    "print('Complement:',dna.complement())\n",
    "print('Reverse complement:', dna.reverse_complement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuAXygo3N_NQ",
    "outputId": "f0f46c5d-ba89-4d0b-88f1-df7cb2e40a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNA: AUGGCCAUUGUAAUGGGCCGCUGAAAGGGUGCCCGAUAG\n"
     ]
    }
   ],
   "source": [
    "# Transcribe coding DNA to RNA\n",
    "rna = dna.transcribe()\n",
    "print('RNA:', rna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sOd2O3cOfzH"
   },
   "source": [
    "Notice that the transcribe function replaces T with U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2xN1Fu1PR2H",
    "outputId": "2a88fcfe-993e-4205-d416-ed21402c2295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA to protein: MAIVMGR*KGAR*\n",
      "RNA to protein: MAIVMGR*KGAR*\n"
     ]
    }
   ],
   "source": [
    "# Translate dna or rna to protein\n",
    "print('DNA to protein:',dna.translate())\n",
    "print('RNA to protein:',rna.translate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppz0iEweGqnk"
   },
   "source": [
    "## One-Hot Encoding\n",
    "For most machine learning applications, DNA or RNA sequence is represented using one-hot encoding. In this schema, each nucleotide is treated as its own class such that DNA sequence would be represented as four classes. Each class/nucleotide has a binary value of 0 (absent) or 1 (present).\n",
    "\n",
    "For example, the sequence `ATGTC` would be encoded as \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1&0&0&0\\\\\n",
    "    0&1&0&0\\\\\n",
    "    0&0&0&1\\\\\n",
    "    0&1&0&0\\\\\n",
    "    0&0&1&0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyPNT09CI8pD"
   },
   "source": [
    "## Exercise\n",
    "Write a function that takes in a sequence of $n$ bases as a string and produces an $n\\times 4$ array where the sequence is represented using one-hot encoding. You may also need to write code to turn the sequence from a string into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "pTLwMwX2Px0e",
    "outputId": "22eda162-3ddb-41a0-860f-82a5b7cb9630",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-291e4012a90a>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    # Encode the sequence with one hot encoding and return a numpy array\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "######## To Do ###########\n",
    "##########################\n",
    "\n",
    "def one_hot_dna(seq):\n",
    "\n",
    "    # Encode the sequence with one hot encoding and return a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhSQPQIGKsqW",
    "outputId": "903296ec-4d68-41ab-a259-6a2cd77a421d",
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_dna(seq):\n",
    "\n",
    "    # Convert seq from string to array\n",
    "    raw = np.array(list(seq))\n",
    "\n",
    "    out = np.zeros((raw.shape[0],4))\n",
    "    out[raw=='A',0] = 1\n",
    "    out[raw=='T',1] = 1\n",
    "    out[raw=='G',2] = 1\n",
    "    out[raw=='C',3] = 1\n",
    "    return out\n",
    "\n",
    "one_hot_dna(dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H21KaLifhv0z"
   },
   "source": [
    "## Processing Branson Sequence Data\n",
    "We'll start by loading all of the sequences from the fasta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVHV0JBQkEuo",
    "outputId": "2940a72b-1824-417e-c0a9-5deb95826c4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94560"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs, lengths = [], []\n",
    "for i,seq_record in enumerate(SeqIO.parse(fname, 'fasta')):\n",
    "    seqs.append(seq_record.seq)\n",
    "    lengths.append(len(seq_record))\n",
    "\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEZj30o6kQ3h"
   },
   "source": [
    "And then taking the alphabetic sequence and turning it into a numeric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SvXmMP0AkVYR"
   },
   "outputs": [],
   "source": [
    "AAs = [\n",
    "        'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H',\n",
    "        'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W',\n",
    "        'Y', 'V', 'X', 'Z', 'J', 'U', 'B', 'Z'\n",
    "    ]\n",
    "vocabulary = { aa: idx + 1 for idx, aa in enumerate(sorted(AAs)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jiWRb4jJlDJp"
   },
   "outputs": [],
   "source": [
    "seq_num = []\n",
    "for s in seqs:\n",
    "    seq_num.append(\n",
    "        [vocabulary[a] for a in s]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sNMYsX3oUSt"
   },
   "source": [
    "Next we check the length of the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czQys-UMnLSU",
    "outputId": "a9c2089f-581e-4546-c4fc-86c1b1fefc70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114, 357, 450, 459, 510, 547, 549, 550, 552, 553, 556, 558, 559,\n",
       "       560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
       "       573, 574, 575, 576])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9thZOtmBoeRB"
   },
   "source": [
    "Most models require that all inputs are the same size, so we need a method to standardize the size of these sequences before using them for training. Intuitively there are two strategies for turning a variable set of sequence lengths into a standard length. First, we can trim all sequences down to the minimum sequence length, but this risks discarding valueable data. Alternatively, we can pad short sequences to the length of the longest sequence. \n",
    "\n",
    "Keras provides a preprocessing [function](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) that handles this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MOiixzhOqfth"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "C4n9DCrSqwJ0"
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(seq_num, maxlen=max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TECWGhi4olQW",
    "outputId": "46ba2956-36b1-4449-8d9d-57174cd5a4f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
      {
      "cell_type": "code",
      "metadata": {
        "id": "2bNbd4_TLCu2",
        "outputId": "acd3c950-85ee-4ff4-f25d-3dc3d550ccf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%load_ext watermark\n",
        "%watermark -u -d -vm --iversions"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last updated: 2021-04-28\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 4.19.112+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "numpy  : 1.19.5\n",
            "Bio    : 1.78\n",
            "IPython: 5.5.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ppz0iEweGqnk"
   ],
   "name": "sequences-key.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}